{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2E2tz3m8Ys1"
   },
   "source": [
    "```\n",
    "BEGIN ASSIGNMENT\n",
    "generate: true\n",
    "files:\n",
    "    - little_women.png\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3m4ZXMY18Ys2"
   },
   "source": [
    "# Tarea 1: Causalidad y Expresiones\n",
    "\n",
    "Completa este libro llenando las celdas provistas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jYQDMEV8Ys3"
   },
   "source": [
    "**Recommended Reading:**\n",
    "- [Qué es la ciencia de datos](http://www.inferentialthinking.com/chapters/01/what-is-data-science.html)\n",
    "- [Causalidad y experimentos](http://www.inferentialthinking.com/chapters/02/causality-and-experiments.html) \n",
    "- [Programando en python](http://www.inferentialthinking.com/chapters/03/programming-in-python.html)\n",
    "\n",
    "Para todos los problemas para los que debes escribir explicaciones y oraciones, **debes** proporcionar su respuesta en el espacio designado. Además, a lo largo de esta tarea y todas las futuras, ¡asegúrate de no reasignar variables en todo el cuaderno! Por ejemplo, si usas `max_temperature` en tu respuesta a una pregunta, no le vuelvas a reasignar esta variable . De lo contrario, reprobarás las pruebas que pensaste que estabas pasando.\n",
    "\n",
    "\n",
    "No está bien compartir las respuestas directamente, pero claro que puedes discutir los problemas con los profesores o con otros estudiantes. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNTOAJna8Ys4"
   },
   "source": [
    "## 1. Aritmética aterradora \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkB_Dym08Ys5"
   },
   "source": [
    "Un anuncio de ADT Security Systems, una compañia de seguridad electrónica, dice:\n",
    "\n",
    "> \"Cuando te vas de vacaciones, los ladrones van a trabajar [...] Según las estadísticas del FBI, más del 25% de los robos en casas ocurren entre el Día de los Caídos y el Día del Trabajo\".\n",
    "\n",
    "¿Los datos del anuncio respaldan la afirmación de que es más probable que los ladrones vayan a trabajar durante el tiempo entre el Día de los Caídos (30 de mayo) y el Día del Trabajo (5 de septiembre)? Por favor explique su respuesta.\n",
    "\n",
    "**Nota:** Puede suponer que \"más del 25 %\" significa solo un poco más. Si hubiera pasado mucho tiempo, digamos más cerca del 30%, los especialistas en marketing lo habrían dicho.\n",
    "\n",
    "```\n",
    "BEGIN QUESTION\n",
    "name: q1\n",
    "manual: True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "export_pdf": true,
    "id": "YP6jGL2R8Ys5"
   },
   "source": [
    "**SOLUCIÓN:** No. El Día del Trabajo es alrededor de 14 semanas después del Día de los Caídos, por lo que el período entre ellos es un poco más del 25% del año (14/52 ~= 26%). El 25% de los robos que ocurren en el 25% del año no implica una mayor tasa de robos en el verano. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iWzkfewl8Ys6"
   },
   "source": [
    "## 2. Los Personajes de  Mujercitas \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPXDPouB8Ys6"
   },
   "source": [
    "En clase, contamos el número de veces que los personajes literarios fueron nombrados en cada capítulo de este libro clásico llamado [*Mujercitas*](https://www.inferentialthinking.com/chapters/01/3/1/literary-characters). En las ciencias de la computación, la palabra \"carácter\" también se refiere a una letra, dígito, espacio o signo de puntuación; cualquier elemento individual de un texto. El siguiente código genera un diagrama de dispersión en el que cada punto corresponde a un capítulo de *Mujercitas*. La posición horizontal de un punto mide el número de signos de puntuación en el capítulo. La posición vertical mide el número total de caracteres. \n",
    "\n",
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "22qMy8dx8Ys8",
    "outputId": "8768113b-d9d6-4ed3-9869-1ba9261fc683",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Esta celda contiene código que aún no se ha visto en el curso ,\n",
    "# pero deberías poder interpretar el diagrama de dispersión que genera .\n",
    "\n",
    "from datascience import *\n",
    "from urllib.request import urlopen\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "little_women_url = 'https://www.inferentialthinking.com/data/little_women.txt'\n",
    "chapters = urlopen(little_women_url).read().decode().split('CHAPTER ')[1:]\n",
    "text = Table().with_column('Chapters', chapters)\n",
    "Table().with_columns(\n",
    "    'Signo de Puntuación',    np.char.count(chapters, '.'),\n",
    "    'Caracteres', text.apply(len, 0)\n",
    "    ).scatter(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2N0Os1r58Ys9"
   },
   "source": [
    "**Pregunta 1.** ¿Cuántos signos de puntuación hay alrededor en el capítulo con más caracteres? Asigne 1, 2, 3, 4 o 5 al nombre `characters_q1` a continuación.\n",
    "\n",
    "1. 250\n",
    "2. 390\n",
    "3. 440\n",
    "4. 32,000\n",
    "5. 40,000 \n",
    "\n",
    "```\n",
    "BEGIN QUESTION\n",
    "name: q2_1\n",
    "manual: false\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "WRNMGtgF8Ys9"
   },
   "outputs": [],
   "source": [
    "characters_q1 = 2 # Solución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YWL2f-kc8Ys-",
    "outputId": "4145a17f-fa6d-4ba5-b629-cc9568bd50b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prueba\n",
    "1 <= characters_q1 <= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "D3lTPM9z8Ys-",
    "outputId": "55c557a2-b2b8-43d5-9331-acfcf91804db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prueba oculta\n",
    "characters_q1 == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mm0uo1wq8Ys_"
   },
   "source": [
    "La prueba anterior verifica que sus respuestas estén en el formato correcto. **Esta prueba no verifica si respondiste correctamente**, sólo que asignaste un número con éxito en cada celda de las opciones de respuesta múltiple. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pOPBYg0N8YtA"
   },
   "source": [
    "**Pregunta 2.** ¿Cuál de los siguientes capítulos tiene el mayor número de caracteres por signo de puntuación? Asigne 1, 2 o 3 al nombre `characters_q2` a continuación.\n",
    "1. El capítulo con alrededor de 60 puntos\n",
    "2. El capítulo con cerca de 350 puntos\n",
    "3. El capítulo con alrededor de 440 puntos \n",
    "\n",
    "```\n",
    "BEGIN QUESTION\n",
    "name: q2_2\n",
    "manual: false\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "o0XV49pZ8YtA"
   },
   "outputs": [],
   "source": [
    "characters_q2 = 1 # SOLUCIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ysjnsOoe8YtB",
    "outputId": "23735e3c-7c8f-4d04-810b-c8636ceaaa6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PRUEBA\n",
    "1 <= characters_q2 <= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E63jTDn68YtB",
    "outputId": "045aae9f-3154-4ffd-9936-40f3d66651f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PRUEBA OCULTA\n",
    "characters_q2 == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "boDZuPTJ8YtC"
   },
   "source": [
    "Nuevamente, la prueba anterior verifica que sus respuestas estén en el formato correcto, pero no que hayas respondido correctamente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOUI9i428YtC"
   },
   "source": [
    "Para descubrir más datos interesantes de este diagrama, lee la [Sección 1.3.2](https://www.inferentialthinking.com/chapters/01/3/2/another-kind-of-character) del texto guía."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BykzuzIQ8YtC"
   },
   "source": [
    "## 3. Nombres y declaraciones de asignación \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5B-Q0rIq8YtC"
   },
   "source": [
    "**Pregunta 1.** Cuando ejecutas la siguiente celda, Python genera un mensaje de error críptico. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UxNkVJiB8YtD",
    "outputId": "d66406d5-5e93-453f-8cb7-68adb7230b53"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to operator (<ipython-input-5-b83b2880b35e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-b83b2880b35e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    2 + 2 =4\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to operator\n"
     ]
    }
   ],
   "source": [
    "4 = 2 + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UhTIY-jQ8YtD"
   },
   "source": [
    "Elije la mejor explicación de lo que está mal con el código y luego asigna `1, 2, 3 o 4` a `names_q1`  para indicar tu respuesta.\n",
    "\n",
    "1. Python es inteligente y ya sabe que `4 = 2 + 2`.\n",
    "\n",
    "2. `4` ya es un número definido, y no tiene sentido hacer que un número sea el nombre de otra cosa. En Python, \"`x = 2 + 2`\" significa \"asignar a `x` como el nombre para el valor de `2 + 2`\".\n",
    "\n",
    "3. Debería ser `2 + 2 = 4`.\n",
    "\n",
    "4. No recibo ningún mensaje de error. Esta es una pregunta con trampa. \n",
    "\n",
    "```\n",
    "BEGIN QUESTION\n",
    "name: q3_1\n",
    "manual: False\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GPI4Bjsy8YtD"
   },
   "outputs": [],
   "source": [
    "names_q1 = 2 # SOLUCIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FBk3-6sY8YtE",
    "outputId": "984f97fc-56d4-43e3-db73-9b0afd15ecb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PRUEBA\n",
    "1 <= names_q1 <= 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D01OnQRO8YtE",
    "outputId": "fc0072d7-e1f8-419b-ca19-c9840d8d2f01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PRUEBA OCULTA\n",
    "names_q1 == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXGUP7hn8YtF"
   },
   "source": [
    "**Pregunta 2.** Cuando ejecutes la siguiente celda, Python generará otro críptico mensaje de error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VGyu6i3M8YtF",
    "outputId": "8b7bb203-62bb-4c88-c599-450183a31e55"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-820d4d61e3dd>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-12-820d4d61e3dd>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    six = two plus two\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "two = 3\n",
    "six = two plus two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HRvo6Qe18YtF"
   },
   "source": [
    "Elije la mejor explicación de lo que está mal con el código y asigne `1, 2, 3 o 4` a `names_q2` para indicar tu respuesta.\n",
    "\n",
    "1. El operador `plus` solo se aplica a los números, no a la palabra \"two\".\n",
    "\n",
    "2. El nombre \"two\" no se puede asignar al número 3.\n",
    "\n",
    "3. Dos más dos son cuatro, no seis.\n",
    "\n",
    "4. Python no puede interpretar el nombre `dos` seguido directamente por un nombre que no ha sido definido. \n",
    "\n",
    "```\n",
    "BEGIN QUESTION\n",
    "name: q3_2\n",
    "manual: False\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gnMgSgR88YtG"
   },
   "outputs": [],
   "source": [
    "names_q2 = 4 # SOLUCIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W2ZE361b8YtG",
    "outputId": "50632fcf-5966-4683-ad25-a22feb739790"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PRUEBA\n",
    "1 <= names_q2 <= 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31JGRnky8YtG",
    "outputId": "195a191b-037b-463a-b475-dd142d10a68f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PRUEBA OCULTA\n",
    "names_q2 == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vUkaLUqV8YtG"
   },
   "source": [
    "**Pregunta 3.** Cuando ejecutes la siguiente celda, Python, una vez más, generará otro mensaje de error críptico. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MYPB7XUJ8YtH",
    "outputId": "f78126e2-3b76-45ca-e311-df82670d8d68",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-94f783b16b3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "x = print(5)\n",
    "y = x + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_lepad28YtH"
   },
   "source": [
    "Elije la mejor explicación de lo que está mal con el código y asigna `1, 2 o 3` a `names_q3`  para indicar tu respuesta.\n",
    "\n",
    "1. Python no quiere que se asigne `y`.\n",
    "\n",
    "2. La operación `print` está destinada a mostrar valores al programador, ¡no a asignar valores!\n",
    "\n",
    "3. Python no puede hacer sumas entre un nombre y un número. Tiene que ser 2 números o 2 nombres predefinidos.. \n",
    "\n",
    "```\n",
    "BEGIN QUESTION\n",
    "name: q3_3\n",
    "manual: false\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cxjJe_TH8YtH"
   },
   "outputs": [],
   "source": [
    "names_q3 = 2 # SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lZlFBUeS8YtI",
    "outputId": "63d7cdd0-c4f3-42a5-e8e1-1f22a85b8c31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "1 <= names_q3 <= 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YtPvMiTs8YtI",
    "outputId": "700edbd4-7853-4ed8-ec53-423e7dad74dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HIDDEN TEST\n",
    "names_q3 == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCImRz1z8YtJ"
   },
   "source": [
    "## 4. Oportunidades de trabajo y educación en la India rural \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDu7Z9OT8YtJ"
   },
   "source": [
    "Un [estudio](http://www.nber.org/papers/w16021.pdf) en la UCLA (Universidad de California en Los Ángeles) investigó los factores que podrían resultar en una mayor atención a la salud y la educación de las niñas en la India rural. Uno de esos factores es la información sobre las oportunidades laborales para las mujeres. La idea es que si las personas saben que las mujeres educadas pueden conseguir buenos trabajos, podrían cuidar más la salud y la educación de las niñas en sus familias, como una inversión, viendo en el futuro  a las niñas como fuente una ptencial fuente de ingresos. Sin el conocimiento de las oportunidades laborales de las mujeres, la autora plantea la hipótesis de que las familias no invierten en el bienestar de las niñas.\n",
    "\n",
    "El estudio se centró en 160 aldeas fuera de la capital de la India, todas con poco acceso a información sobre centros de llamadas y organizaciones similares que ofrecen oportunidades laborales a las mujeres. En 80 de las aldeas elegidas al azar, reclutadores visitaron la aldea, describieron las oportunidades de trabajo, reclutaron mujeres que tenían algún dominio del idioma inglés y experiencia con computadoras, y brindaron apoyo continuo, gratis, durante tres años. En las otras 80 aldeas, ningún reclutador visitó y no se realizó ninguna otra intervención.\n",
    "\n",
    "Al final del período de estudio, los investigadores registraron datos sobre la asistencia escolar y la salud de los niños de las aldeas. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jcng7gwQ8YtJ"
   },
   "source": [
    "**Pregunta 1.** ¿Qué afirmación describe mejor los grupos de *tratamiento* y *control* para este estudio? Asigne 1, 2 o 3 al nombre `jobs_q1` a continuación.\n",
    "\n",
    "1. El grupo de tratamiento fueron las 80 aldeas visitadas por los reclutadores, y el grupo de control fueron las otras 80 aldeas sin intervención.\n",
    "\n",
    "2. El grupo de tratamiento fueron las 160 aldeas seleccionadas y el grupo de control el resto de las aldeas fuera de la capital de la India.\n",
    "\n",
    "3. No hay una noción clara de grupo de *tratamiento* y *control* en este estudio. \n",
    "\n",
    "```\n",
    "BEGIN QUESTION\n",
    "name: q4_1\n",
    "manual: false\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iYWg135W8YtJ"
   },
   "outputs": [],
   "source": [
    "jobs_q1 = 1 # SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hwlPOQIe8YtK",
    "outputId": "69bbd96f-f6b4-4bc5-ba8b-c16255b58efa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "1 <= jobs_q1 <= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "riAn8H_y8YtK",
    "outputId": "8a07d3a7-644d-4ad7-9ece-fb59ce082b3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HIDDEN TEST\n",
    "jobs_q1 == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdTqhl8N8YtK"
   },
   "source": [
    "**Pregunta 2.** ¿Fue este un estudio observacional o un experimento aleatorio controlado? Asigne 1, 2 o 3 al nombre `jobs_q2` a continuación.\n",
    "\n",
    "1. Este fue un estudio observacional.\n",
    "\n",
    "2. Este fue un experimento controlado aleatorio.\n",
    "\n",
    "3. Este fue un estudio observacional aleatorizado. \n",
    "\n",
    "```\n",
    "BEGIN QUESTION\n",
    "name: q4_2\n",
    "manual: false\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NA-qOABo8YtL"
   },
   "outputs": [],
   "source": [
    "jobs_q2 = 2 # SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cc8ndc4x8YtL",
    "outputId": "e57704a2-dfa4-4bd2-9b32-cab273212156"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "1 <= jobs_q2 <= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PMSaWggm8YtL",
    "outputId": "a092039a-c64c-4511-f758-3b45ac72bd5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HIDDEN TEST\n",
    "jobs_q2 == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0M2ibpm8YtM"
   },
   "source": [
    "**Pregunta 3.** El estudio informó: \"Las niñas de 5 a 15 años en las aldeas que recibieron los servicios de los reclutadores tenían de 3 a 5 puntos porcentuales más probabilidades de asistir a la escuela y experimentaron un aumento en el índice de masa corporal, lo que refleja una mejor nutrición y/ o atención médica. Sin embargo, no hubo una ganancia neta en altura. Para los niños, no hubo cambios en ninguna de estas medidas\". ¿Por qué crees que el autor señala la falta de cambio en los niños?\n",
    "\n",
    "*Pista:* Recuerda la hipótesis original. El autor cree que educar a las mujeres sobre las oportunidades laborales hará que las familias inviertan más en el bienestar de las mujeres. \n",
    "\n",
    "```\n",
    "BEGIN QUESTION\n",
    "name: q4_3\n",
    "manual: true\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "export_pdf": true,
    "id": "8bEqMUU38YtN"
   },
   "source": [
    "**SOLUCIÓN:** La falta de cambios en el bienestar de los niños es evidencia de que el tratamiento, dirigido a las mujeres, fue de hecho la razón del efecto observado. Si el bienestar de los niños también hubiera mejorado, una explicación alternativa para el efecto observado sería que fue el resultado de un aumento general en el bienestar y la prosperidad en estos pueblos (factores de confusión), en lugar del tratamiento de reclutamiento. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjJsTnlY8YtN"
   },
   "source": [
    "## 5. Diferencias entre diferentes carreras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YhA7JydR8YtN"
   },
   "source": [
    "La Oficina de Planificación y Análisis de Berkeley proporciona datos sobre numerosos aspectos del campus. Adaptado del sitio web de OPA, la siguiente tabla muestra el número de graduados en tres carreras en los años académicos 2008-2009 y 2017-2018. \n",
    "\n",
    "| Carrera                            | 2008-2009    | 2017-2018   |\n",
    "|------------------------------------|--------------|-------------|\n",
    "| Estudios de género y de la mujer          |      17      |    28       |\n",
    "| Lingüística                        |      49      |    67       |\n",
    "| Retórica                           |      113     |    56       |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYgPmwoT8YtO"
   },
   "source": [
    "**Pregunta 1.** Supón que se desea encontrar la **mayor** diferencia absoluta entre el número de graduados en los dos años, entre las tres especialidades.\n",
    "\n",
    "En la celda a continuación, calcula este valor y llámalo `biggest_change`. Usa una sola expresión (una sola línea de código) para calcular la respuesta. Deje que Python realice toda la aritmética (como restar 49 de 67) en lugar de simplificar la expresión por tí mismo. La función incorporada `abs`  toma una entrada numérica y devuelve el valor absoluto. La función incorporada `max`  puede tomar 3 argumentos y devuelve el máximo de los tres números \n",
    "\n",
    "```\n",
    "BEGIN QUESTION\n",
    "name: q5_1\n",
    "manual: True\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "export_pdf": true,
    "id": "B7Fs7kya8YtO",
    "outputId": "7fdaddda-d32c-49b1-e89b-a234707e970f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biggest_change = max(abs(17 - 28), abs(49 - 67), abs(113 - 56)) #SOLUTION\n",
    "biggest_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-3Jsh-m68YtO",
    "outputId": "18063852-d515-45a3-8e52-d07a1a90485f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "isinstance(biggest_change,(int, float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lnbxVqoI8YtO",
    "outputId": "704e0d3f-f6ae-4236-fb66-2fc1d27788c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HIDDEN TEST\n",
    "biggest_change == 57"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXGZ6A2q8YtP"
   },
   "source": [
    "**Pregunta 2.** ¿Cuál de las tres carreras principales tuvo la **menor** diferencia absoluta? Asigne `smallest_change_major` a 1, 2 o 3 donde cada número corresponde a la siguiente especialidad:\n",
    "\n",
    "1: Estudios de género y de la mujer\n",
    "2: Lingüística\n",
    "3: retórica\n",
    "\n",
    "Elije el número que corresponda a la carrera con la diferencia absoluta más pequeña.\n",
    "\n",
    "Deberías poder responder con aritmética mental aproximada, sin tener que calcular el valor exacto para cada especialidad. \n",
    "\n",
    "```\n",
    "BEGIN QUESTION\n",
    "name: q5_2\n",
    "manual: False\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NqQtCKjx8YtP",
    "outputId": "17778fce-3d4b-405b-fb53-37a775ef1f60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smallest_change_major = 1 # SOLUTION\n",
    "smallest_change_major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aaQVTmAN8YtP",
    "outputId": "c6dbb625-594c-4ad8-b562-cda35444d1d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "isinstance(smallest_change_major, (int, float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q8layJ_68YtQ",
    "outputId": "d22d9936-bffd-4b1c-f93f-afe68eeedb27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HIDDEN TEST\n",
    "smallest_change_major == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PfwoE_fj8YtQ"
   },
   "source": [
    "**Pregunta 3.** Para cada especialidad, defina el \"cambio relativo\" de la siguiente manera:  $\\large{\\frac{\\text{diferencia absoluta}}{\\text{valor en 2008-2009}} * 100}$ \n",
    "\n",
    "Fill in the code below such that `gws_relative_change`, `linguistics_relative_change` and `rhetoric_relative_change` are assigned to the relative changes for their respective majors.\n",
    "\n",
    "```\n",
    "BEGIN QUESTION\n",
    "name: q5_3\n",
    "manual: False\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "for_assignment_type": "student",
    "id": "iPoM228A8YtR",
    "outputId": "dec87e8d-3e44-4dd8-aa6c-eb422b87aa08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64.70588235294117, 36.734693877551024, 50.442477876106196)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# BEGIN PROMPT\n",
    "gws_relative_change = (abs(...) / 17) * 100\n",
    "\"\"\"; # END PROMPT\n",
    "gws_relative_change = (abs(17 - 28) / 17) * 100 # SOLUTION NO PROMPT \n",
    "linguistics_relative_change = (abs(49 - 67) / 49) * 100 # SOLUTION\n",
    "rhetoric_relative_change = (abs(113 - 56) / 113) * 100 # SOLUTION\n",
    "gws_relative_change, linguistics_relative_change, rhetoric_relative_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pDI_AT_S8YtR",
    "outputId": "34004dab-5bfb-4785-840f-646375a55ac9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "isinstance(gws_relative_change, (int, float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6esu69UV8YtR",
    "outputId": "44c087c7-457d-4e77-ab7b-49fca5be3e73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "isinstance(linguistics_relative_change, (int, float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bCUEZdia8YtR",
    "outputId": "7ae81393-3041-4983-ce87-64139839caa9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "isinstance(rhetoric_relative_change, (int, float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5Z3H1TG8YtR",
    "outputId": "389ff9b5-d671-442e-9494-bc4320522872"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HIDDEN TEST\n",
    "gws_relative_change >= 64 and gws_relative_change <= 66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d7SFI6Wv8YtS",
    "outputId": "7ef8f338-2bd7-40fe-985e-c41f6cf9c473"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HIDDEN TEST\n",
    "linguistics_relative_change >= 36 and linguistics_relative_change <= 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f0dcLxsF8YtS",
    "outputId": "3ae11881-e64e-4bd7-d932-eeb34ff4d3f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HIDDEN TEST\n",
    "rhetoric_relative_change >= 50 and rhetoric_relative_change <= 52"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UoPqyOF8YtS"
   },
   "source": [
    "**Pregunta 4.** Asigne a `biggest_rel_change_major` los valores 1, 2 o 3 donde cada número corresponde a lo siguiente:\n",
    "\n",
    "1: Estudios de género y de la mujer\n",
    "2: Lingüística\n",
    "3: Retórica\n",
    "\n",
    "Elija el número que corresponda a la carrera con el mayor cambio relativo. \n",
    "\n",
    "```\n",
    "BEGIN QUESTION\n",
    "name: q5_4\n",
    "manual: False\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PfTIgSaj8YtT",
    "outputId": "a22a195e-eae6-4c08-b4f8-5bf19675d3f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign biggest_rel_change_major to the number corresponding to the major with the biggest relative change.\n",
    "biggest_rel_change_major = 1 # SOLUTION\n",
    "biggest_rel_change_major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dafnDOXx8YtT",
    "outputId": "b7abe686-184c-471c-9d6c-f938e9f3ba12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "isinstance(biggest_rel_change_major, (int, float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mtZdAWhq8YtT",
    "outputId": "14ac1a53-aeb8-444d-b8a9-2a0bb382c2fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HIDDEN TEST\n",
    "biggest_rel_change_major == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jihaj6eq8YtU"
   },
   "source": [
    "## 6. Estudio sobre la  miopía \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EB6E7I_l8YtU"
   },
   "source": [
    "La miopía es el resultado de una serie de factores genéticos y ambientales. En 1999, Quinn et al estudiaron la relación entre la miopía y la iluminación ambiental nocturna (por ejemplo, de luces nocturnas o de habitaciones) durante la infancia. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7f74gh08YtU"
   },
   "source": [
    "**Pregunta 1.** Los datos fueron recopilados mediante el siguiente procedimiento, informado en el estudio. \"Entre enero y junio de 1998, los padres de niños de 2 a 16 años [...] que fueron atendidos como pacientes externos en una clínica universitaria de oftalmología pediátrica completaron un cuestionario sobre la exposición a la luz del niño tanto en la actualidad como antes de los 2 años. \" ¿Este estudio fue observacional o fue un experimento controlado? Explica. \n",
    "\n",
    "```\n",
    "BEGIN QUESTION\n",
    "name: q6_1\n",
    "manual: True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "export_pdf": true,
    "id": "QKFyz8p98YtU"
   },
   "source": [
    "**SOLUCIÓN:** Fue un estudio observacional. Los investigadores no realizaron ninguna intervención. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIVq9KJL8YtU"
   },
   "source": [
    "**Pregunta 2.** El estudio encontró que de los niños que dormían con la luz de la habitación encendida antes de los 2 años, el 55 % eran miopes. De los niños que dormían con una luz de noche encendida antes de los 2 años, el 34% eran miopes. De los niños que dormían en la oscuridad antes de los 2 años, el 10% eran miopes. El estudio concluyó que \"la prevalencia de la miopía [...] durante la infancia estuvo fuertemente asociada con la exposición a la luz ambiental durante el sueño nocturno en los primeros dos años después del nacimiento\".\n",
    "\n",
    "¿Los datos respaldan esta afirmación? Puedes interpretar \"fuertemente\" de cualquier manera cualitativa razonable. \n",
    "\n",
    "```\n",
    "BEGIN QUESTION\n",
    "name: q6_2\n",
    "manual: True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "export_pdf": true,
    "id": "Scc2Rox38YtV"
   },
   "source": [
    "**SOLUCIÓN:** Sí. Hay una gran diferencia en las tasas de miopía entre los grupos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6m9nOXQ8YtV"
   },
   "source": [
    "**Pregunta 3.** El 13 de mayo de 1999, CNN reportó los resultados de este estudio bajo el título: \"La luz nocturna puede causar miopía\". ¿La conclusión del estudio afirma que la luz nocturna causa miopía? \n",
    "\n",
    "```\n",
    "BEGIN QUESTION\n",
    "name: q6_3\n",
    "manual: True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "export_pdf": true,
    "id": "_d72_v-H8YtV"
   },
   "source": [
    "**SOLUCIÓN:** No. El estudio (como se mencionó anteriormente) afirmó que había sólo una asociación. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wv7eW-Ph8YtV"
   },
   "source": [
    "**Pregunta 4.** El párrafo final del informe de CNN decía que \"varios oftalmólogo\" habían señalado que el estudio debería haber tenido en cuenta la herencia genética.\n",
    "\n",
    "La miopía se transmite de padres a hijos. Los padres miopes tienen más probabilidades de tener hijos miopes, y también es más probable que dejen las luces encendidas habitualmente (ya que los padres tienen mala visión). ¿De qué manera el conocimiento de este posible vínculo genético afecta la forma en que interpretamos los datos del estudio? \n",
    "\n",
    "```\n",
    "BEGIN QUESTION\n",
    "name: q6_4\n",
    "manual: True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "export_pdf": true,
    "id": "_kllMJk08YtW"
   },
   "source": [
    "**SOLUCIÓN:** Si llegara a ser más probable que los padres miopes tengan hijos miopes _y_ dejen las luces encendidas por la noche, entonces es más probable que los niños miopes tengan luces encendidas por la noche. Entonces es razonable suponer que los padres miopes son un posible factor de confusión que el estudio observacional no tuvo en cuenta. Sin embargo, todavía podemos encontrar la asociación observada incluso si no hay un efecto causal de las luces nocturnas en la miopía infantil. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdAFcENP8YtX"
   },
   "source": [
    "## 7. Estudiando a los sobrevivientes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IeugFqeQ8YtX"
   },
   "source": [
    "El reverendo Henry Whitehead se mostró escéptico ante la conclusión de John Snow sobre la bomba de Broad Street. Después de que terminó la epidemia de cólera de Broad Street, Whitehead se dispuso a intentar demostrar que Snow estaba equivocado. (La historia del evento se detalla [aquí](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1034367/pdf/medhist00183-0026.pdf).)\n",
    "\n",
    "Se dio cuenta de que Snow había centrado su análisis casi por completo en los que habían muerto. Whitehead, por lo tanto, investigó los hábitos de hidratación de las personas en el área de Broad Street que no habían muerto en el brote.\n",
    "\n",
    "¿Cuál es la razón principal por la que fue importante estudiar a este grupo?\n",
    "\n",
    "1) Si Whitehead hubiera descubierto que muchas personas habían bebido agua de la bomba de Broad Street y no contrajeron cólera, eso habría sido evidencia en contra de la hipótesis de Snow.\n",
    "\n",
    "2) Los sobrevivientes podrían proporcionar información adicional sobre qué más podría haber causado el cólera, lo que podría descubrir otra causa.\n",
    "\n",
    "3) Al considerar a los sobrevivientes, Whitehead podría haber identificado una cura para el cólera.\n",
    "\n",
    "```\n",
    "BEGIN QUESTION\n",
    "name: q7_1\n",
    "manual: False\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sl78sFE18YtX"
   },
   "outputs": [],
   "source": [
    "# Assign survivor_answer to 1, 2, or 3\n",
    "survivor_answer = 1 # SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NqfePD6O8YtY",
    "outputId": "ccdba35b-1308-4daf-dee6-bd5dcb8bd2cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST \n",
    "1 <= survivor_answer <= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BHvDcuOU8YtY",
    "outputId": "54a92156-bc72-4172-fa2c-133a815a1f70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HIDDEN TEsT\n",
    "survivor_answer == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HwV0juJ_8YtY"
   },
   "source": [
    "**Nota:** Whitehead terminó encontrando más pruebas de que la bomba de Broad Street desempeñó un papel central en la propagación de la enfermedad a las personas que vivían cerca de ella. Con el tiempo, se convirtió en uno de los más grandes defensores de Snow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7krEuOd8YtY"
   },
   "source": [
    "## 8. Términos y condiciones  y Administrivia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBxiAlyZ8YtZ"
   },
   "source": [
    "This section of the homework is to ensure that you have read over the policies and frequently asked questions for the course. \n",
    "\n",
    "**It's important that you read through this section of the homework very carefully**. If you can get through all of this section and are sure you have all of the correct resources set up, you will be able to focus on the actual material this semester!\n",
    "\n",
    "Reading through the [policies](http://data8.org/sp20/policies.html) and the [FAQ](http://data8.org/sp20/faq.html) will help you get through this section very easily. It is recommended you do this before. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4aVbCkdt8YtZ"
   },
   "source": [
    "**Question 1:** You have a question regarding the grading of your assignments that has not been previously answered on Piazza or the FAQ. Who do you contact? Assign `contact` to the number corresponding to the best choice below. \n",
    "\n",
    "1. The Instructors\n",
    "2. Post on Piazza\n",
    "3. Contact your Lab TA\n",
    "\n",
    "```\n",
    "BEGIN QUESTION\n",
    "name: q8_1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sKUOeqg-8YtZ"
   },
   "outputs": [],
   "source": [
    "contact = 3 # SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yfkIQusA8YtZ",
    "outputId": "913e517c-845e-46ac-95c8-7fa2df960183"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "contact == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oTs4-k8k8YtZ"
   },
   "source": [
    "**Question 2:** Why will the grades on Gradescope and OkPy be different? Assign `grades` to the number corresponding to the best choice below. \n",
    "\n",
    "1. There was a mistake in the grading. I should contact someone about this\n",
    "2. Gradescope grades the written portion, while OkPy grades the coded portion\n",
    "3. Trick question; the grades should be the same on both platforms\n",
    "\n",
    "```\n",
    "BEGIN QUESTION\n",
    "name: q8_2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rX2xlIAs8YtZ"
   },
   "outputs": [],
   "source": [
    "grades = 2 # SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sW7WIM6z8Yta",
    "outputId": "b4e7a6fe-a1bb-4258-9336-382d7fc54454"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "grades == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JD72UQNs8Yta"
   },
   "source": [
    "**Question 3:** Regrade deadline dates will always be posted on the same Piazza post that releases the assignment grades, common mistakes, and solutions. Can you ask for parts of your assignment regraded after the regrade request window has passed? Assign `regrade` to the number corresponding to the best choice below. \n",
    "\n",
    "1. Yes\n",
    "2. No\n",
    "\n",
    "```\n",
    "BEGIN QUESTION\n",
    "name: q8_3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cS1m4qX78Ytc"
   },
   "outputs": [],
   "source": [
    "regrade = 2 # SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "futY53KF8Ytc",
    "outputId": "784492ed-4056-435d-e429-a49e403639f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "regrade == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlxQaNMp8Ytd"
   },
   "source": [
    "**Question 4:** Do you have an Gradescope account? Head to [gradescope.com](http://gradescope.com) and check if you see Data 8. If you do not, please send your Lab TA an email with your email and student ID number. \n",
    "\n",
    "Once you have been enrolled, go to the Data 8 Gradescope course website. At the end of the url (link), you should see a number. Assign `gradescope` to that number. \n",
    "\n",
    "```\n",
    "BEGIN QUESTION\n",
    "name: q8_4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uoIIEeqp8Ytd"
   },
   "outputs": [],
   "source": [
    "gradescope = 82441 # SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zpXH8RNr8Ytd",
    "outputId": "3d3706ac-6b1e-44a6-d3c2-afc780296433"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "gradescope == 82441"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sYAQUt068Ytd"
   },
   "source": [
    "**Question 5:** Given the following scenarios, assign `acceptable` to the number of the scenario that is permissible given the guidelines on the [policies](http://data8.org/sp20/policies.html) page. \n",
    "\n",
    "1. Alice gets stuck on a homework assignment, so she googles a fix. She stumbles across a pdf of the solutions for the homework assignment from a previous semester's offering of Data 8. After inspecting the solution, Alice writes her own solution and submits the assignment.\n",
    "\n",
    "2. After getting confused by a project, Bob asks his friend for help. His friend helps by walking the student through his own logic, pointing out areas that are important given the context of the question. Upon hearing his friends logic, the Bob writes his own code and completes the project.\n",
    "\n",
    "3. Eve has an extremely busy schedule, so she really wants to leave lab early by finishing it and getting checked off. Her neighbor, Charlie, simply turns his computer so Eve can see how he completed some questions. After looking at his code, Eve finishes the lab and gets checked off.\n",
    "\n",
    "```\n",
    "BEGIN QUESTION\n",
    "name: q8_5\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MxFnV1zf8Ytd"
   },
   "outputs": [],
   "source": [
    "acceptable = 2 # SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OeMdo-mz8Yte",
    "outputId": "b935a665-f2d5-41cc-817a-9843c133dfbd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "acceptable == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibwYzLR48Yte"
   },
   "source": [
    "**Question 6:** To make sure you have read through the [policies](http://data8.org/sp20/policies.html) and the [FAQ](http://data8.org/sp20/faq.html) carefully, how many HW/lab drops are there? Assign `drops` to the number corresponding to the best choice below. \n",
    "\n",
    "1. Two homework drops and one lab drop\n",
    "2. One homework drop and one lab drop\n",
    "3. Only one homework drop\n",
    "\n",
    "```\n",
    "BEGIN QUESTION\n",
    "name: q8_6\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "itwXuUIE8Yte"
   },
   "outputs": [],
   "source": [
    "drops = 1 # SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJ0tjyz58Yte",
    "outputId": "f180ea36-6208-4423-8dff-2c820ff1fa89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "drops == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "maQ9IYhi8Ytf"
   },
   "source": [
    "**Question 7:** Does Data 8 offer any alternate exams? Assign `exams` to the number corresponding to the best choice below. \n",
    "\n",
    "1. Yes\n",
    "2. No\n",
    "\n",
    "```\n",
    "BEGIN QUESTION\n",
    "name: q8_7\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oN14T-Qx8Ytf"
   },
   "outputs": [],
   "source": [
    "exams = 2 # SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "itCRtyjr8Ytf",
    "outputId": "78db9519-4f54-4661-de5b-b8b8ae72f954"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "exams == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uk3SvXjX8Ytf"
   },
   "source": [
    "**Question 8:** Are you actually checking Piazza? Go to this semester's [Data 8 Piazza](https://piazza.com/class/k5fwiw4wql642x), and find an instructor posted thread with a certain secret phrase. Assign `secret` to this secret phrase in quotes (aka as a string).\n",
    "\n",
    "```\n",
    "BEGIN QUESTION\n",
    "name: q8_8\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QCzU1iOs8Ytg"
   },
   "outputs": [],
   "source": [
    "secret = \"tacotuesday\" # SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mb4k0A6r8Ytg",
    "outputId": "87562dcd-8f62-4dd1-eba9-9051221597bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "# Please actually go on Piazza and look at the threads.\n",
    "# Looks like you didn't make a string.\n",
    "type(secret) == str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MsjfIOi58Ytg",
    "outputId": "9455b688-d04d-4ff8-e327-b1a1de27cadf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "len(secret) == 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zh7fgzz38Yth",
    "outputId": "e3abc345-ea6b-4033-b0ca-56fee09940b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HIDDEN TEST\n",
    "secret == \"tacotuesday\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7yAJeMe8Yth"
   },
   "source": [
    "## 9. Welcome Survey\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XA7m_MD8Yth"
   },
   "source": [
    "Once you have submitted, please also complete the welcome survey in order to receive credit for homework 1.\n",
    "\n",
    "Welcome survey is here: https://docs.google.com/forms/d/e/1FAIpQLSd28-DvELnGk4n6lHcqMOWcsovDulNSbhmlLFXqDMQIsdldaQ/viewform?usp=sf_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tNFgJz18Yti"
   },
   "source": [
    "Assign `survey` to the secret string given at the end of the welcome survey:\n",
    "```\n",
    "BEGIN QUESTION\n",
    "name: q9\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nyj4jvOb8Yti"
   },
   "outputs": [],
   "source": [
    "survey = \"2020 vision\" # SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Urrz73jj8Yti",
    "outputId": "d934ba68-281b-428d-b146-ea24626d64bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "survey == \"2020 vision\""
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "colab": {
   "name": "hw01_trad_esp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
